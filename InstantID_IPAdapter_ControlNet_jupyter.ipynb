{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexmaks/n8n/blob/master/InstantID_IPAdapter_ControlNet_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "15248c64-e4b8-47df-bd08-a300ddfb37ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/content/TotoroUI'...\n",
            "remote: Enumerating objects: 20484, done.\u001b[K\n",
            "remote: Total 20484 (delta 0), reused 0 (delta 0), pack-reused 20484 (from 1)\u001b[K\n",
            "Receiving objects: 100% (20484/20484), 71.55 MiB | 15.50 MiB/s, done.\n",
            "Resolving deltas: 100% (13651/13651), done.\n",
            "Cloning into '/content/TotoroUI/IPAdapter'...\n",
            "remote: Enumerating objects: 733, done.\u001b[K\n",
            "remote: Counting objects: 100% (376/376), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 733 (delta 356), reused 270 (delta 270), pack-reused 357 (from 1)\u001b[K\n",
            "Receiving objects: 100% (733/733), 4.71 MiB | 12.01 MiB/s, done.\n",
            "Resolving deltas: 100% (490/490), done.\n",
            "Cloning into '/content/TotoroUI/InstantID'...\n",
            "remote: Enumerating objects: 160, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 160 (delta 68), reused 64 (delta 64), pack-reused 87 (from 1)\u001b[K\n",
            "Receiving objects: 100% (160/160), 1.61 MiB | 4.51 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.2/757.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext==0.17.1 (from versions: 0.1.1, 0.2.0, 0.2.1, 0.2.3, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.16.2, 0.16.2+cpu, 0.17.2, 0.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext==0.17.1\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m128.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for xformers (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n",
            "\u001b[0mThe following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "85186f|\u001b[1;32mOK\u001b[0m  |   121MiB/s|/content/TotoroUI/models/raemuXL_v35Lightning.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "a98502|\u001b[1;32mOK\u001b[0m  |   211MiB/s|/content/TotoroUI/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "8bff15|\u001b[1;32mOK\u001b[0m  |   269MiB/s|/content/TotoroUI/models/ipadapter/ip-adapter-plus-face_sdxl_vit-h.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "add5e1|\u001b[1;32mOK\u001b[0m  |   176MiB/s|/content/TotoroUI/models/controlnet/thibaud_xl_openpose.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "5b7531|\u001b[1;32mOK\u001b[0m  |   169MiB/s|/content/TotoroUI/models/sdxl_resizer.pt\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "434c24|\u001b[1;32mOK\u001b[0m  |   266MiB/s|/content/TotoroUI/models/insightface/models/antelopev2/1k3d68.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "38ccc0|\u001b[1;32mOK\u001b[0m  |    37MiB/s|/content/TotoroUI/models/insightface/models/antelopev2/2d106det.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "f7ed13|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/TotoroUI/models/insightface/models/antelopev2/genderage.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "908cd2|\u001b[1;32mOK\u001b[0m  |   259MiB/s|/content/TotoroUI/models/insightface/models/antelopev2/glintr100.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "15bf0c|\u001b[1;32mOK\u001b[0m  |    54MiB/s|/content/TotoroUI/models/insightface/models/antelopev2/scrfd_10g_bnkps.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "29e942|\u001b[1;32mOK\u001b[0m  |   202MiB/s|/content/TotoroUI/models/instantid/ip-adapter.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "dc6454|\u001b[1;32mOK\u001b[0m  |   204MiB/s|/content/TotoroUI/models/controlnet/SDXL/instantid/diffusion_pytorch_model.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "--2025-12-10 10:16:33--  https://huggingface.co/camenduru/IICF/resolve/main/test/anya.jpg\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.109.52, 18.238.109.92, 18.238.109.121, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.109.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /api/resolve-cache/models/camenduru/IICF/54e0d03579ecbe437b97f8c8b743b2963e6b36bf/test%2Fanya.jpg?%2Fcamenduru%2FIICF%2Fresolve%2Fmain%2Ftest%2Fanya.jpg=&etag=%22e1d673f0f6136e970943bf3dec06136b0ed60cde%22 [following]\n",
            "--2025-12-10 10:16:33--  https://huggingface.co/api/resolve-cache/models/camenduru/IICF/54e0d03579ecbe437b97f8c8b743b2963e6b36bf/test%2Fanya.jpg?%2Fcamenduru%2FIICF%2Fresolve%2Fmain%2Ftest%2Fanya.jpg=&etag=%22e1d673f0f6136e970943bf3dec06136b0ed60cde%22\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78694 (77K) [image/jpeg]\n",
            "Saving to: ‘/content/anya.jpg’\n",
            "\n",
            "/content/anya.jpg   100%[===================>]  76.85K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-12-10 10:16:33 (7.57 MB/s) - ‘/content/anya.jpg’ saved [78694/78694]\n",
            "\n",
            "--2025-12-10 10:16:33--  https://huggingface.co/camenduru/IICF/resolve/main/test/pose_images.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.168.132.91, 3.168.132.126, 3.168.132.38, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.168.132.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/665d290c2080b38e5d528e79/ebc60237cb84d3279077b080058abcb1e703e6d75a37d1cbae8246e709af6998?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T101633Z&X-Amz-Expires=3600&X-Amz-Signature=682ae6b6b4f6fd77a95a6217ae7f060815b68f7ce02e50cf4d6b162c154be0c5&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pose_images.zip%3B+filename%3D%22pose_images.zip%22%3B&response-content-type=application%2Fzip&x-id=GetObject&Expires=1765365393&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2NTM5M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjVkMjkwYzIwODBiMzhlNWQ1MjhlNzkvZWJjNjAyMzdjYjg0ZDMyNzkwNzdiMDgwMDU4YWJjYjFlNzAzZTZkNzVhMzdkMWNiYWU4MjQ2ZTcwOWFmNjk5OCoifV19&Signature=kaKHUm98VLUszCh4Kp8c1j2%7E7s6LkUsBgMTZ9d-48XnwFyIyfFBTaNfwSDvpHfYvs1GAq9srgbIswVteFdd3Tbj3ozqSEVUgaggULP3l3llGXFkUMaiN9G8r4vJknpMOm682D%7Eh-Pchg0RlljT72n1HY9t9prKEGQ2wjrE-QPtlk3lNlUhF69ElN1ZyYSKNsTqjMoUYFuZx1dMhccxihj2obFlrdlP7wJ71v13b966O9fz%7EA%7EjCTzGi-MfEO-8Pv8HfVWmbzbnOmTC3zCw2bze2Zvfq9LYMrszW8%7ECCzUq7M0NFShKIkoFNvNQCJ8amW8YxZFIG9RvhvrexEvGCwaA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-12-10 10:16:33--  https://cas-bridge.xethub.hf.co/xet-bridge-us/665d290c2080b38e5d528e79/ebc60237cb84d3279077b080058abcb1e703e6d75a37d1cbae8246e709af6998?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T101633Z&X-Amz-Expires=3600&X-Amz-Signature=682ae6b6b4f6fd77a95a6217ae7f060815b68f7ce02e50cf4d6b162c154be0c5&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pose_images.zip%3B+filename%3D%22pose_images.zip%22%3B&response-content-type=application%2Fzip&x-id=GetObject&Expires=1765365393&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2NTM5M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjVkMjkwYzIwODBiMzhlNWQ1MjhlNzkvZWJjNjAyMzdjYjg0ZDMyNzkwNzdiMDgwMDU4YWJjYjFlNzAzZTZkNzVhMzdkMWNiYWU4MjQ2ZTcwOWFmNjk5OCoifV19&Signature=kaKHUm98VLUszCh4Kp8c1j2%7E7s6LkUsBgMTZ9d-48XnwFyIyfFBTaNfwSDvpHfYvs1GAq9srgbIswVteFdd3Tbj3ozqSEVUgaggULP3l3llGXFkUMaiN9G8r4vJknpMOm682D%7Eh-Pchg0RlljT72n1HY9t9prKEGQ2wjrE-QPtlk3lNlUhF69ElN1ZyYSKNsTqjMoUYFuZx1dMhccxihj2obFlrdlP7wJ71v13b966O9fz%7EA%7EjCTzGi-MfEO-8Pv8HfVWmbzbnOmTC3zCw2bze2Zvfq9LYMrszW8%7ECCzUq7M0NFShKIkoFNvNQCJ8amW8YxZFIG9RvhvrexEvGCwaA__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 3.168.86.69, 3.168.86.41, 3.168.86.92, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|3.168.86.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2585058 (2.5M) [application/zip]\n",
            "Saving to: ‘/content/pose_images.zip’\n",
            "\n",
            "/content/pose_image 100%[===================>]   2.46M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-12-10 10:16:34 (26.1 MB/s) - ‘/content/pose_images.zip’ saved [2585058/2585058]\n",
            "\n",
            "Archive:  /content/pose_images.zip\n",
            "   creating: pose_images/\n",
            "  inflating: pose_images/headshot_dw_pose_00001_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00002_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00003_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00004_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00005_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00006_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00007_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00008_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00009_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00010_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00011_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00012_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00013_.png  \n",
            "  inflating: pose_images/headshot_dw_pose_00014_.png  \n",
            "  inflating: pose_images/headshot_kps_00001_.png  \n",
            "  inflating: pose_images/headshot_kps_00002_.png  \n",
            "  inflating: pose_images/headshot_kps_00003_.png  \n",
            "  inflating: pose_images/headshot_kps_00004_.png  \n",
            "  inflating: pose_images/headshot_kps_00005_.png  \n",
            "  inflating: pose_images/headshot_kps_00006_.png  \n",
            "  inflating: pose_images/headshot_kps_00007_.png  \n",
            "  inflating: pose_images/headshot_kps_00008_.png  \n",
            "  inflating: pose_images/headshot_kps_00009_.png  \n",
            "  inflating: pose_images/headshot_kps_00010_.png  \n",
            "  inflating: pose_images/headshot_kps_00011_.png  \n",
            "  inflating: pose_images/headshot_kps_00012_.png  \n",
            "  inflating: pose_images/headshot_kps_00013_.png  \n",
            "  inflating: pose_images/headshot_kps_00014_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00001_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00002_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00003_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00004_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00005_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00006_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00007_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00008_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00009_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00010_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00011_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00012_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00013_.png  \n",
            "  inflating: pose_images/headshot_open_pose_00014_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00001_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00002_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00003_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00004_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00005_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00006_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00007_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00008_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00009_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00010_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00011_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00012_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00013_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00014_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00015_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00016_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00017_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00018_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00019_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00020_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00021_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00022_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00023_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00024_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00025_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00026_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00027_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00028_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00029_.png  \n",
            "  inflating: pose_images/pose_dw_pose_00030_.png  \n",
            "  inflating: pose_images/pose_kps_00001_.png  \n",
            "  inflating: pose_images/pose_kps_00002_.png  \n",
            "  inflating: pose_images/pose_kps_00003_.png  \n",
            "  inflating: pose_images/pose_kps_00004_.png  \n",
            "  inflating: pose_images/pose_kps_00005_.png  \n",
            "  inflating: pose_images/pose_kps_00006_.png  \n",
            "  inflating: pose_images/pose_kps_00007_.png  \n",
            "  inflating: pose_images/pose_kps_00008_.png  \n",
            "  inflating: pose_images/pose_kps_00009_.png  \n",
            "  inflating: pose_images/pose_kps_00010_.png  \n",
            "  inflating: pose_images/pose_kps_00011_.png  \n",
            "  inflating: pose_images/pose_kps_00012_.png  \n",
            "  inflating: pose_images/pose_kps_00013_.png  \n",
            "  inflating: pose_images/pose_kps_00014_.png  \n",
            "  inflating: pose_images/pose_kps_00015_.png  \n",
            "  inflating: pose_images/pose_kps_00016_.png  \n",
            "  inflating: pose_images/pose_kps_00017_.png  \n",
            "  inflating: pose_images/pose_kps_00018_.png  \n",
            "  inflating: pose_images/pose_kps_00019_.png  \n",
            "  inflating: pose_images/pose_kps_00020_.png  \n",
            "  inflating: pose_images/pose_kps_00021_.png  \n",
            "  inflating: pose_images/pose_kps_00022_.png  \n",
            "  inflating: pose_images/pose_kps_00023_.png  \n",
            "  inflating: pose_images/pose_kps_00024_.png  \n",
            "  inflating: pose_images/pose_kps_00025_.png  \n",
            "  inflating: pose_images/pose_kps_00026_.png  \n",
            "  inflating: pose_images/pose_kps_00027_.png  \n",
            "  inflating: pose_images/pose_kps_00028_.png  \n",
            "  inflating: pose_images/pose_kps_00029_.png  \n",
            "  inflating: pose_images/pose_kps_00030_.png  \n",
            "  inflating: pose_images/pose_open_pose_00001_.png  \n",
            "  inflating: pose_images/pose_open_pose_00002_.png  \n",
            "  inflating: pose_images/pose_open_pose_00003_.png  \n",
            "  inflating: pose_images/pose_open_pose_00004_.png  \n",
            "  inflating: pose_images/pose_open_pose_00005_.png  \n",
            "  inflating: pose_images/pose_open_pose_00006_.png  \n",
            "  inflating: pose_images/pose_open_pose_00007_.png  \n",
            "  inflating: pose_images/pose_open_pose_00008_.png  \n",
            "  inflating: pose_images/pose_open_pose_00009_.png  \n",
            "  inflating: pose_images/pose_open_pose_00010_.png  \n",
            "  inflating: pose_images/pose_open_pose_00011_.png  \n",
            "  inflating: pose_images/pose_open_pose_00012_.png  \n",
            "  inflating: pose_images/pose_open_pose_00013_.png  \n",
            "  inflating: pose_images/pose_open_pose_00014_.png  \n",
            "  inflating: pose_images/pose_open_pose_00015_.png  \n",
            "  inflating: pose_images/pose_open_pose_00016_.png  \n",
            "  inflating: pose_images/pose_open_pose_00017_.png  \n",
            "  inflating: pose_images/pose_open_pose_00018_.png  \n",
            "  inflating: pose_images/pose_open_pose_00019_.png  \n",
            "  inflating: pose_images/pose_open_pose_00020_.png  \n",
            "  inflating: pose_images/pose_open_pose_00021_.png  \n",
            "  inflating: pose_images/pose_open_pose_00022_.png  \n",
            "  inflating: pose_images/pose_open_pose_00023_.png  \n",
            "  inflating: pose_images/pose_open_pose_00024_.png  \n",
            "  inflating: pose_images/pose_open_pose_00025_.png  \n",
            "  inflating: pose_images/pose_open_pose_00026_.png  \n",
            "  inflating: pose_images/pose_open_pose_00027_.png  \n",
            "  inflating: pose_images/pose_open_pose_00028_.png  \n",
            "  inflating: pose_images/pose_open_pose_00029_.png  \n",
            "  inflating: pose_images/pose_open_pose_00030_.png  \n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b totoro https://github.com/camenduru/ComfyUI /content/TotoroUI\n",
        "!git clone -b totoro_v2 https://github.com/camenduru/ComfyUI_IPAdapter_plus /content/TotoroUI/IPAdapter\n",
        "!git clone -b totoro https://github.com/camenduru/ComfyUI_InstantID /content/TotoroUI/InstantID\n",
        "\n",
        "!pip install -q torch==2.2.1+cu121 torchvision==0.17.1+cu121 torchaudio==2.2.1+cu121 torchtext==0.17.1 torchdata==0.7.1 --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.25 insightface onnxruntime onnxruntime-gpu\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/470847 -d /content/TotoroUI/models -o raemuXL_v35Lightning.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors -d /content/TotoroUI/models/clip_vision -o CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus-face_sdxl_vit-h.safetensors  -d /content/TotoroUI/models/ipadapter -o ip-adapter-plus-face_sdxl_vit-h.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/thibaud_xl_openpose.safetensors -d /content/TotoroUI/models/controlnet -o thibaud_xl_openpose.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://github.com/Ttl/ComfyUi_NNLatentUpscale/raw/master/sdxl_resizer.pt -d /content/TotoroUI/models -o sdxl_resizer.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/DIAMONIK7777/antelopev2/resolve/main/1k3d68.onnx -d /content/TotoroUI/models/insightface/models/antelopev2 -o 1k3d68.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/DIAMONIK7777/antelopev2/resolve/main/2d106det.onnx -d /content/TotoroUI/models/insightface/models/antelopev2 -o 2d106det.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/DIAMONIK7777/antelopev2/resolve/main/genderage.onnx -d /content/TotoroUI/models/insightface/models/antelopev2 -o genderage.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/DIAMONIK7777/antelopev2/resolve/main/glintr100.onnx -d /content/TotoroUI/models/insightface/models/antelopev2 -o glintr100.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/DIAMONIK7777/antelopev2/resolve/main/scrfd_10g_bnkps.onnx -d /content/TotoroUI/models/insightface/models/antelopev2 -o scrfd_10g_bnkps.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/InstantX/InstantID/resolve/main/ip-adapter.bin -d /content/TotoroUI/models/instantid -o ip-adapter.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/InstantX/InstantID/resolve/main/ControlNetModel/diffusion_pytorch_model.safetensors -d /content/TotoroUI/models/controlnet/SDXL/instantid -o diffusion_pytorch_model.safetensors\n",
        "\n",
        "!wget https://huggingface.co/camenduru/IICF/resolve/main/test/anya.jpg -O /content/anya.jpg\n",
        "!wget https://huggingface.co/camenduru/IICF/resolve/main/test/pose_images.zip -O /content/pose_images.zip\n",
        "!unzip /content/pose_images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sjdfEsIDuTpt",
        "outputId": "68cf29bb-0aa1-4814-bdef-4fddfacc19a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TotoroUI\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchsde'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2294228900.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtotoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/TotoroUI/IPAdapter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TotoroUI/nodes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtotoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusers_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtotoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtotoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtotoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TotoroUI/totoro/samplers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mk_diffusion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mk_diffusion_sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextra_samplers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muni_pc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtotoro\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_management\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TotoroUI/totoro/k_diffusion/sampling.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchsde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsde'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "%cd /content/TotoroUI\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import totoro\n",
        "import nodes\n",
        "import sys\n",
        "sys.path.append('/content/TotoroUI/IPAdapter')\n",
        "import IPAdapterPlus\n",
        "sys.path.append('/content/TotoroUI/InstantID')\n",
        "import InstantID\n",
        "import scipy\n",
        "import model_management\n",
        "from latent_resizer import LatentResizer\n",
        "from totoro import model_management\n",
        "import gc\n",
        "import random\n",
        "\n",
        "def upscale(latent, upscale):\n",
        "  device = model_management.get_torch_device()\n",
        "  samples = latent.to(device=device, dtype=torch.float16)\n",
        "  model = LatentResizer.load_model('/content/TotoroUI/models/sdxl_resizer.pt', device, torch.float16)\n",
        "  model.to(device=device)\n",
        "  latent_out = (model(0.13025 * samples, scale=upscale) / 0.13025)\n",
        "  latent_out = latent_out.to(device=\"cpu\")\n",
        "  model.to(device=model_management.vae_offload_device())\n",
        "  return ({\"samples\": latent_out},)\n",
        "\n",
        "with torch.no_grad():\n",
        "    model_patcher, clip, vae, clipvision = totoro.sd.load_checkpoint_guess_config(\"/content/TotoroUI/models/raemuXL_v35Lightning.safetensors\", output_vae=True, output_clip=True, embedding_directory=None)\n",
        "    IPAdapterPlus_model = IPAdapterPlus.IPAdapterUnifiedLoader().load_models(model_patcher, 'PLUS FACE (portraits)', lora_strength=0.0, provider=\"CUDA\")\n",
        "    instantid = InstantID.InstantIDModelLoader().load_model(\"/content/TotoroUI/models/instantid/ip-adapter.bin\")\n",
        "    insightface = InstantID.InstantIDFaceAnalysis().load_insight_face(\"CUDA\")\n",
        "    instantid_control_net = totoro.controlnet.load_controlnet(\"/content/TotoroUI/models/controlnet/SDXL/instantid/diffusion_pytorch_model.safetensors\")\n",
        "    output_image, output_mask = nodes.LoadImage().load_image(\"/content/anya.jpg\")\n",
        "    image_kps, image_kps_mask = nodes.LoadImage().load_image(\"/content/pose_images/pose_kps_00008_.png\")\n",
        "    image_dw, image_dw_mask = nodes.LoadImage().load_image(\"/content/pose_images/pose_dw_pose_00008_.png\")\n",
        "    ip_model_patcher = IPAdapterPlus.IPAdapterAdvanced().apply_ipadapter(IPAdapterPlus_model[0], IPAdapterPlus_model[1], image=output_image, weight_type=\"style transfer\")\n",
        "    tokens = clip.tokenize(\"1girl\")\n",
        "    cond, pooled = clip.encode_from_tokens(tokens, return_pooled=True)\n",
        "    cond = [[cond, {\"pooled_output\": pooled}]]\n",
        "    n_tokens = clip.tokenize(\"(nsfw:1.5), nipple, nude, naked, lowres, child, getty, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name, trademark, watermark, title, multiple view, reference sheet, mutated hands and fingers, poorly drawn face, mutation, deformed, ugly, bad proportions, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, tatoo, amateur drawing, odd eyes, uneven eyes, unnatural face, uneven nostrils, crooked mouth, bad teeth, crooked teeth, photoshop, video game, censor, censored, ghost, b&w, weird colors, gradient background, spotty background, blurry background, ugly background, simple background, realistic, out of frame, extra objects, gross, ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of focus, blurry, very long body, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn eyes, cloned face, disfigured, deformed, cross-eye, extra limbs, missing limb, malformed hands, mutated, morbid, mutilated, disfigured, extra arms, extra hands, mangled fingers, contorted, conjoined, mismatched limbs, mismatched parts, bad perspective, black and white, oversaturated, undersaturated, bad shadow, cropped image, draft, grainy, pixelated\")\n",
        "    n_cond, n_pooled = clip.encode_from_tokens(n_tokens, return_pooled=True)\n",
        "    n_cond = [[n_cond, {\"pooled_output\": n_pooled}]]\n",
        "    work_model, instantid_cond, instantid_n_cond = InstantID.ApplyInstantID().apply_instantid(instantid=instantid[0], insightface=insightface[0], control_net=instantid_control_net, image=output_image, model=ip_model_patcher[0], positive=cond, negative=n_cond, start_at=0.0, end_at=1.0, weight=0.80, image_kps=image_kps)\n",
        "    openpose_control_net = totoro.controlnet.load_controlnet(\"/content/TotoroUI/models/controlnet/thibaud_xl_openpose.safetensors\")\n",
        "    openpose_cond = nodes.ControlNetApply().apply_controlnet(conditioning=instantid_cond, control_net=openpose_control_net, image=image_dw, strength=0.90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-ikaeJ3kuTpu",
        "outputId": "abfd0b45-beea-45b8-a5a9-7e0321508a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_management' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-284011919.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclipvision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mIPAdapterPlus_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_empty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_management' is not defined"
          ]
        }
      ],
      "source": [
        "instantid = None\n",
        "insightface = None\n",
        "instantid_control_net = None\n",
        "ip_model_patcher = None\n",
        "cond = None\n",
        "n_cond = None\n",
        "model_patcher = None\n",
        "clip = None\n",
        "clipvision = None\n",
        "IPAdapterPlus_model = None\n",
        "model_management.cleanup_models()\n",
        "gc.collect()\n",
        "model_management.soft_empty_cache()\n",
        "\n",
        "ran = random.randint(0, 65535)\n",
        "print(ran)\n",
        "\n",
        "with torch.no_grad():\n",
        "    latent = {\"samples\":torch.zeros([1, 4, 1024 // 8, 1024 // 8])}\n",
        "    sample = nodes.common_ksampler(model=work_model,\n",
        "                          seed=ran,\n",
        "                          steps=4,\n",
        "                          cfg=1.3,\n",
        "                          sampler_name=\"dpmpp_sde_gpu\",\n",
        "                          scheduler=\"karras\",\n",
        "                          positive=openpose_cond[0],\n",
        "                          negative=instantid_n_cond,\n",
        "                          latent=latent,\n",
        "                          denoise=0.95)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        sample = sample[0][\"samples\"].to(torch.float16)\n",
        "        vae.first_stage_model.cuda()\n",
        "        decoded = vae.decode_tiled(sample).detach()\n",
        "\n",
        "Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvWza6lHuTpu"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  latent = upscale(sample, 1.5)\n",
        "  sample = nodes.common_ksampler(model=work_model,\n",
        "                            seed=ran,\n",
        "                            steps=4,\n",
        "                            cfg=1.3,\n",
        "                            sampler_name=\"dpmpp_sde_gpu\",\n",
        "                            scheduler=\"karras\",\n",
        "                            positive=openpose_cond[0],\n",
        "                            negative=instantid_n_cond,\n",
        "                            latent=latent[0],\n",
        "                            denoise=0.55)\n",
        "  with torch.inference_mode():\n",
        "    sample = sample[0][\"samples\"].to(torch.float16)\n",
        "    vae.first_stage_model.cuda()\n",
        "    decoded = vae.decode_tiled(sample).detach()\n",
        "Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}